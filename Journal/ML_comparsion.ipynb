{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\"\"\"\n",
    "membrane_stress = 2 \n",
    "bending_stress = 3 \n",
    "\n",
    "\"\"\"\n",
    "section_row = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/umutozdemir/comparison-of-different-regression-models\n",
    "# https://www.kaggle.com/stuarthallows/using-xgboost-with-scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   data_length  signal.welch.mean_x  signal.welch.std_x  signal.welch.max_x  \\\n",
      "0          0.0                  0.0                 1.0                 1.0   \n",
      "1          0.0                  0.0                 1.0                 1.0   \n",
      "2          0.0                  0.0                 1.0                 1.0   \n",
      "3          0.0                  0.0                 1.0                 1.0   \n",
      "4          0.0                  0.0                 1.0                 1.0   \n",
      "\n",
      "   signal.welch.min_x  welch_ave_roll_mean_10_x  welch_std_roll_mean_10_x  \\\n",
      "0                -1.0                       0.0                      -1.0   \n",
      "1                -1.0                       0.0                      -1.0   \n",
      "2                -1.0                       0.0                      -1.0   \n",
      "3                -1.0                       0.0                      -1.0   \n",
      "4                -1.0                       0.0                      -1.0   \n",
      "\n",
      "   welch_max_roll_mean_10_x  welch_min_roll_mean_10_x  \\\n",
      "0                       0.0                       1.0   \n",
      "1                       0.0                       1.0   \n",
      "2                       0.0                       1.0   \n",
      "3                       0.0                       1.0   \n",
      "4                       0.0                       1.0   \n",
      "\n",
      "   welch_ave_roll_std_10_x  ...  fft_max_roll_std_10_z  fft_min_roll_std_10_z  \\\n",
      "0                      1.0  ...                    0.0                    1.0   \n",
      "1                      1.0  ...                    0.0                    1.0   \n",
      "2                      1.0  ...                    0.0                    1.0   \n",
      "3                      1.0  ...                    0.0                    1.0   \n",
      "4                      1.0  ...                    0.0                    1.0   \n",
      "\n",
      "   fft_ave_roll_mean_500_z  fft_std_roll_mean_500_z  fft_max_roll_mean_500_z  \\\n",
      "0                     -1.0                      1.0                      1.0   \n",
      "1                     -1.0                      1.0                      1.0   \n",
      "2                     -1.0                      1.0                      1.0   \n",
      "3                     -1.0                      1.0                      1.0   \n",
      "4                     -1.0                      1.0                      1.0   \n",
      "\n",
      "   fft_min_roll_mean_500_z  fft_ave_roll_std_500_z  fft_std_roll_std_500_z  \\\n",
      "0                      1.0                     0.0                     0.0   \n",
      "1                      1.0                     0.0                     0.0   \n",
      "2                      1.0                     0.0                     0.0   \n",
      "3                      1.0                     0.0                     0.0   \n",
      "4                      1.0                     0.0                     0.0   \n",
      "\n",
      "   fft_max_roll_std_500_z  fft_min_roll_std_500_z  \n",
      "0                     1.0                     1.0  \n",
      "1                     1.0                     1.0  \n",
      "2                     1.0                     1.0  \n",
      "3                     1.0                     1.0  \n",
      "4                     1.0                     1.0  \n",
      "\n",
      "[5 rows x 133 columns]\n"
     ]
    }
   ],
   "source": [
    "#x_data = pd.read_csv(\"scaled_data_x_data.csv\")\n",
    "x_data = pd.read_csv(\"x_data.csv\")\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_data)\n",
    "x_data = pd.DataFrame(scaler.transform(x_data), columns=x_data.columns)\n",
    "print(x_data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13 entries, 0 to 12\n",
      "Columns: 133 entries, data_length to fft_min_roll_std_500_z\n",
      "dtypes: float64(133)\n",
      "memory usage: 13.6 KB\n"
     ]
    }
   ],
   "source": [
    "x_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7521 entries, 0 to 7520\n",
      "Data columns (total 1 columns):\n",
      "y__data    7521 non-null float32\n",
      "dtypes: float32(1)\n",
      "memory usage: 408.1 KB\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "train_test_split    \n",
    "\"\"\"\n",
    "\n",
    "pd_data_input_y = pd.read_csv(\"7521number_final_output_data.csv\")\n",
    "# y_data_input_y = pd_data_input_y.read_excel['path1_membrane_SINT'].values.tolist()\n",
    "\n",
    "y_data = pd.DataFrame(dtype=np.float32, columns=['y__data'])\n",
    "\n",
    "for i in range(0, 7521):\n",
    "    # for i in range(len(pd_data_input_y)):\n",
    "    y_data.loc[i, 'y__data'] = pd_data_input_y.iloc[i, section_row] * 10000\n",
    "    # print(y_data.loc[i, 'y__data'])\n",
    "\n",
    "# print(\"train_y\",y_data)\n",
    "y_data.to_csv('data.csv', index=False)\n",
    "y_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 133)\n",
      "(7521, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_data.shape)\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [13, 7521]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4e393d7a0f8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2116\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid parameters passed: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2118\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2120\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \"\"\"\n\u001b[1;32m    247\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [13, 7521]"
     ]
    }
   ],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(x_data, y_data, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(xtest.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Start "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "\n",
    "scores = cross_val_score(lin_reg, x_data, y_data, cv=10, n_jobs=-1, scoring = \"neg_mean_squared_error\")\n",
    "lin_rmse_scores = np.sqrt(-scores)\n",
    "LR_result = lin_rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_reg_ridge = Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_sgd_ridge = cross_val_score(sgd_reg_ridge, x_data, y_data, cv=10, n_jobs=-1, scoring = \"neg_mean_squared_error\")\n",
    "sgd_ridge_rmse_scores = np.sqrt(-scores_sgd_ridge)\n",
    "Ridge_result = sgd_ridge_rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "sgd_reg_lasso = Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_sgd_lasso = cross_val_score(sgd_reg_lasso, x_data, y_data, cv=10, n_jobs=-1, scoring = \"neg_mean_squared_error\")\n",
    "scores_sgd_lasso_rmse_scores = np.sqrt(-scores_sgd_lasso)\n",
    "Lasso_result = scores_sgd_lasso_rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_reg = ElasticNet(random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_elastic_reg = cross_val_score(elastic_reg, x_data, y_data, cv=10, n_jobs=-1, scoring = \"neg_mean_squared_error\")\n",
    "scores_elastic_reg_rmse_scores = np.sqrt(-scores_elastic_reg)\n",
    "ElasticNet_result = scores_elastic_reg_rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. SVR - Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_reg_poly = SVR(kernel = \"poly\", degree = 2, C=1, epsilon = 0)\n",
    "scores_svm_poly = cross_val_score(svm_reg_poly, x_data, y_data, cv=10, n_jobs=-1, scoring = \"neg_mean_squared_error\")\n",
    "\n",
    "svm_reg_poly_scores = np.sqrt(-scores_svm_poly)\n",
    "svr_poly_result = svm_reg_poly_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. SVR - RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_reg_rbf = SVR(kernel = \"rbf\", C=1)\n",
    "scores_svm_rbf = cross_val_score(svm_reg_rbf, x_data, y_data, cv=10, n_jobs=-1, scoring = \"neg_mean_squared_error\")\n",
    "\n",
    "svm_reg_rbf_scores = np.sqrt(-scores_svm_rbf)\n",
    "svr_rbf_kernel_result = svm_reg_rbf_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFR = RandomForestRegressor()\n",
    "scores_RFR = cross_val_score(RFR, x_data, y_data, cv=10, n_jobs=-1, scoring = \"neg_mean_squared_error\")\n",
    "\n",
    "scores_RFR_scores = np.sqrt(-scores_RFR)\n",
    "RF_result = scores_RFR_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. XGBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb_model = xgboost.XGBRegressor()\n",
    "scores_xgb = cross_val_score(best_xgb_model, x_data, y_data, cv=10, n_jobs=-1, scoring = \"neg_mean_squared_error\")\n",
    "scores_xgb_scores = np.sqrt(-scores_xgb)\n",
    "xgr_result = scores_xgb_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb_model.fit(xtrain, ytrain, early_stopping_rounds=10, eval_set=[(xtest, ytest)], verbose=False)\n",
    "xgboost.plot_importance(best_xgb_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = lgb.LGBMRegressor()\n",
    "scores_lgbm = cross_val_score(lgbm, x_data, y_data, cv=10, n_jobs=-1, scoring = \"neg_mean_squared_error\")\n",
    "scores_lgbm_scores = np.sqrt(-scores_lgbm)\n",
    "lgbm_result = scores_lgbm_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. XGBoost Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(xtrain, label=ytrain)\n",
    "dtest = xgb.DMatrix(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_evaluate(max_depth, gamma, colsample_bytree):\n",
    "    params = {'eval_metric': 'rmse',\n",
    "              'max_depth': int(max_depth),\n",
    "              'subsample': 0.8,\n",
    "              'eta': 0.1,\n",
    "              'gamma': gamma,\n",
    "              'colsample_bytree': colsample_bytree}\n",
    "    # Used around 1000 boosting rounds in the full model\n",
    "    cv_result = xgb.cv(params, dtrain, num_boost_round=100, nfold=3)    \n",
    "    \n",
    "    # Bayesian optimization only knows how to maximize, not minimize, so return the negative RMSE\n",
    "    return -1.0 * cv_result['test-rmse-mean'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_bo = BayesianOptimization(xgb_evaluate, {'max_depth': (3, 7), \n",
    "                                             'gamma': (0, 1),\n",
    "                                             'colsample_bytree': (0.3, 0.9)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(xgb_bo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb_bo.maximize(init_points=10, n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, res in enumerate(xgb_bo.res):\n",
    "    print('Iteration {} : \\n\\t{}'.format(i,res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final result : \", xgb_bo.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(xgb_bo.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb2 = xgb.train(xgb_bo.max, dtrain , 100)\n",
    "#lgb2 = lgb.train(params, d_train, 100)\n",
    "xgb_prob = xgb2.predict( dtest )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "opt_xgb_result = np.sqrt(mean_squared_error(ytest, xgb_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb2 = xgb.train(xgb_bo.max, dtrain , 100)\n",
    "#lgb2 = lgb.train(params, d_train, 100)\n",
    "xgb_prob = xgb2.predict( dtest )\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "np.sqrt(mean_squared_error(ytest, xgb_prob))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fix,ax = plt.subplots(figsize = (10,20))\n",
    "plot_importance(xgb2, ax = ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=[LR_result,Ridge_result,Lasso_result,ElasticNet_result,svr_poly_result,svr_rbf_kernel_result,RF_result,\n",
    "xgr_result,lgbm_result,opt_xgb_result]\n",
    "AlgorthmsName=[\"LR_result\",\"Ridge_result\",\"Lasso_result\",\"ElasticNet_result\",\"svr_poly_result\",\"svr_rbf_kernel_result\",\"RF_result\"\n",
    ",\"xgr_result\",\"lgbm_result\",\"opt_xgb_result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotly\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import itertools\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    x = AlgorthmsName,\n",
    "    y= scores,\n",
    "    name='Algortms Name',\n",
    "    marker =dict(color='rgba(0,255,0,0.5)',\n",
    "               line =dict(color='rgb(0,0,0)',width=2)),\n",
    "                text=AlgorthmsName\n",
    ")\n",
    "data = [trace1]\n",
    "\n",
    "layout = go.Layout(barmode = \"group\",\n",
    "                  xaxis= dict(title= 'ML Algorithms',ticklen= 5,zeroline= False),\n",
    "              yaxis= dict(title= 'Prediction Scores',ticklen= 5,zeroline= False))\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = px.data.iris() \n",
    "iris.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cf. LHBM Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def bayes_parameter_opt_lgb(X, y, init_round=15, opt_round=25, n_folds=5, random_seed=0, n_estimators=10000, learning_rate=0.05, output_process=False):\n",
    "    # prepare data\n",
    "    train_data = lgb.Dataset(data=X, label=y, categorical_feature = list(X.columns),free_raw_data=False)\n",
    "    # parameters\n",
    "\n",
    "    def lgb_eval(num_leaves, feature_fraction, max_depth , min_split_gain, min_child_weight):\n",
    "        params = {\n",
    "            \"objective\" : \"regression\", \"bagging_fraction\" : 0.8, \"bagging_freq\": 1,\n",
    "            \"min_child_samples\": 20, \"reg_alpha\": 1, \"reg_lambda\": 1,\"boosting\": \"rf\",\n",
    "            \"learning_rate\" : 0.01, \"subsample\" : 0.8, \"colsample_bytree\" : 0.8, \"verbosity\": -1, \"metric\" : 'rmse'\n",
    "        }\n",
    "        params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
    "        params['max_depth'] = int(round(max_depth))\n",
    "        params['num_leaves'] = int(round(num_leaves))\n",
    "        params['min_split_gain'] = min_split_gain\n",
    "        params['min_child_weight'] = min_child_weight\n",
    "        cv_result = lgb.cv(params, train_data, nfold=n_folds, seed=random_seed, verbose_eval =200,stratified=False)\n",
    "        return (-1.0 * np.array(cv_result['rmse-mean'])).max()\n",
    "    \n",
    "        # range \n",
    "    lgbBO = BayesianOptimization(lgb_eval, {'feature_fraction': (0.1, 0.9),\n",
    "                                            'max_depth': (5, 9),\n",
    "                                            'num_leaves' : (200,300),\n",
    "                                            'min_split_gain': (0.001, 0.1),\n",
    "                                            'min_child_weight': (5, 50)}, random_state=0)\n",
    "        # optimize\n",
    "    lgbBO.maximize(init_points=init_round, n_iter=opt_round,acq='ei')\n",
    "\n",
    "        # output optimization process\n",
    "    if output_process==True: lgbBO.points_to_csv(\"bayes_opt_result.csv\")\n",
    "\n",
    "        # return best parameters\n",
    "    return lgbBO\n",
    "\n",
    "opt_params = bayes_parameter_opt_lgb(x_data, y_data, init_round=10, opt_round=10, n_folds=5, random_seed=0, n_estimators=1000, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(opt_params.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_bo.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = lgb.Dataset(xtrain,label=ytrain)\n",
    "dtest = lgb.Dataset(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params1 = {\"objective\" : \"regression\", \"metric\" : \"rmse\", \n",
    "               \"feature_fraction\": 0.7941654378759639,\n",
    "               \"min_split_gain\" : 0.025580954346285312,\n",
    "               \"min_child_weight\" : 49.94864050157583,\n",
    "               \"max_depth\": 9, \"min_child_samples\": 20, \"reg_alpha\": 1, \"reg_lambda\": 1,\n",
    "               \"num_leaves\" : 201, \"learning_rate\" : 0.01, \"subsample\" : 0.8, \n",
    "               \"colsample_bytree\" : 0.8, \"verbosity\": -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb2 = lgb.train(opt_params.max, dtrain , 100)\n",
    "lgb_prob = lgb2.predict( xtest.values )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "np.sqrt(mean_squared_error(ytest, lgb_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cf. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildclassifier():\n",
    "    classifier = Sequential() #initialize NN\n",
    "    classifier.add(Dense(units = 80, kernel_initializer = 'uniform',activation = 'tanh', input_dim =xtrain.shape[1]))\n",
    "    classifier.add(Dense(units = 40, kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    classifier.add(Dense(units = 20, kernel_initializer = 'uniform',activation = 'relu'))\n",
    "    classifier.add(Dense(units = 10, kernel_initializer = 'uniform',activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform',activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam',loss = 'mean_squared_error')\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasRegressor(build_fn = buildclassifier, epochs = 200)\n",
    "scores_AL = cross_val_score(estimator = classifier, X = xtrain, y= ytrain, cv = 10, scoring = \"neg_mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_AL_scores = np.sqrt(-scores_AL)\n",
    "scores_AL_scores.mean()\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))\n",
    "print(\"Accuracy variance: \"+ str(variance))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
